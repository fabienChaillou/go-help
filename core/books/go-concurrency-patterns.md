Le billet de blog ["Go Concurrency Patterns: Pipelines and Cancellation"](https://go.dev/blog/pipelines) introduit deux concepts essentiels de la programmation concurrente en Go : les **pipelines** et la **cancellation**. Voici une explication claire et structurÃ©e de ces concepts.

---

## ğŸ”„ 1. Pipelines en Go

### âœ… DÃ©finition

Un **pipeline** est une chaÃ®ne de fonctions connectÃ©es entre elles via des **canaux (`chan`)**, oÃ¹ la sortie d'une fonction est l'entrÃ©e de la suivante.

### ğŸ“¦ Exemple simple

Imaginons trois Ã©tapes :

* **GÃ©nÃ©rateur** : produit une sÃ©quence de nombres.
* **CarrÃ©** : calcule le carrÃ© de chaque nombre.
* **Affichage** : affiche les rÃ©sultats.

```go
func gen(nums ...int) <-chan int {
    out := make(chan int)
    go func() {
        for _, n := range nums {
            out <- n
        }
        close(out)
    }()
    return out
}

func square(in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        for n := range in {
            out <- n * n
        }
        close(out)
    }()
    return out
}

func main() {
    for n := range square(gen(2, 3, 4)) {
        fmt.Println(n)
    }
}
```

Chaque Ã©tape tourne dans sa propre goroutine, et les donnÃ©es circulent via les canaux. On a ainsi un flux asynchrone, non bloquant, mais contrÃ´lable.

---

## âŒ 2. Cancellation (annulation)

### âœ… Pourquoi ?

Sans cancellation, les goroutines peuvent rester bloquÃ©es pour toujours, en attente dâ€™Ã©crire ou de lire sur un canal fermÃ© ou ignorÃ©. Cela entraÃ®ne des **goroutines orphelines** et des **fuites mÃ©moire**.

### ğŸ›‘ MÃ©canisme

On utilise un **canal `done <-chan struct{}`** pour signaler lâ€™annulation Ã  tous les composants du pipeline.

### ğŸ§± Exemple modifiÃ© avec cancellation

```go
func gen(done <-chan struct{}, nums ...int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for _, n := range nums {
            select {
            case out <- n:
            case <-done:
                return
            }
        }
    }()
    return out
}

func square(done <-chan struct{}, in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for {
            select {
            case n, ok := <-in:
                if !ok {
                    return
                }
                out <- n * n
            case <-done:
                return
            }
        }
    }()
    return out
}
```

Et dans le `main` :

```go
func main() {
    done := make(chan struct{})
    defer close(done)

    in := gen(done, 2, 3, 4)
    out := square(done, in)

    for n := range out {
        fmt.Println(n)
        // on pourrait dÃ©cider de fermer done ici si une condition est remplie
    }
}
```

---

## ğŸ§  RÃ©sumÃ©

| Concept          | Description                                                                              |
| ---------------- | ---------------------------------------------------------------------------------------- |
| **Pipeline**     | ChaÃ®ne de traitements oÃ¹ chaque Ã©tape a sa propre goroutine et communique via des canaux |
| **Cancellation** | Permet d'arrÃªter proprement les goroutines en utilisant un canal `done`                  |

---

### Squaring number
Bien sÃ»r ! Le concept de **"Squaring numbers"** signifie simplement **Ã©lever chaque nombre au carrÃ©**, câ€™est-Ã -dire multiplier un nombre par lui-mÃªme.

---

## ğŸ“ DÃ©finition mathÃ©matique

Pour un nombre `n`, son carrÃ© est :

$$
n^2 = n \times n
$$

Par exemple :

* $2^2 = 4$
* $3^2 = 9$
* $4^2 = 16$

---

## ğŸ§‘â€ğŸ’» En Go (Golang)

Dans un pipeline de Go, **squaring numbers** est souvent une Ã©tape de transformation. Voici un exemple de fonction qui prend un canal d'entrÃ©e (`in`) et renvoie un canal de sortie (`out`) contenant les carrÃ©s :

```go
func square(in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        for n := range in {
            out <- n * n
        }
        close(out)
    }()
    return out
}
```

### ğŸ”„ Comment Ã§a marche

* `in <-chan int` : canal en lecture seule contenant des entiers.
* `out chan int` : canal en Ã©criture pour les rÃ©sultats.
* La goroutine lit chaque nombre depuis `in`, calcule le carrÃ© (`n * n`), puis l'envoie dans `out`.

---

## ğŸ§ª Exemple complet

```go
func gen(nums ...int) <-chan int {
    out := make(chan int)
    go func() {
        for _, n := range nums {
            out <- n
        }
        close(out)
    }()
    return out
}

func square(in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        for n := range in {
            out <- n * n
        }
        close(out)
    }()
    return out
}

func main() {
    for n := range square(gen(2, 3, 4)) {
        fmt.Println(n)
    }
}
```

### ğŸ–¨ï¸ RÃ©sultat affichÃ© :

```
4
9
16
```

---

## Fan-in Fan-out
Bien sÃ»r ! En Go, les **patterns de concurrence** appelÃ©s **fan-out** et **fan-in** sont trÃ¨s utilisÃ©s pour parallÃ©liser et agrÃ©ger des tÃ¢ches. Voici une explication claire de chacun.

---

## ğŸ”€ 1. Fan-Out

### âœ… DÃ©finition

**Fan-out** signifie **distribuer un travail sur plusieurs goroutines** pour exÃ©cuter des tÃ¢ches en parallÃ¨le.

### ğŸ¯ Objectif

* **AccÃ©lÃ©rer le traitement** en exÃ©cutant plusieurs opÃ©rations simultanÃ©ment.
* RÃ©partir les donnÃ©es entrantes vers plusieurs workers.

### ğŸ§  Illustration

Imaginons une fonction `square` qui reÃ§oit un flux de nombres, et on veut parallÃ©liser ce calcul :

```go
func square(done <-chan struct{}, in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for {
            select {
            case n, ok := <-in:
                if !ok {
                    return
                }
                out <- n * n
            case <-done:
                return
            }
        }
    }()
    return out
}
```

Dans le `main`, on peut lancer plusieurs workers :

```go
done := make(chan struct{})
defer close(done)

in := gen(2, 3, 4, 5, 6, 7)

// Fan-out : 2 workers lisent en parallÃ¨le depuis le mÃªme canal `in`
c1 := square(done, in)
c2 := square(done, in)
```

---

## ğŸ” 2. Fan-In

### âœ… DÃ©finition

**Fan-in** signifie **rassembler les rÃ©sultats de plusieurs goroutines** dans un seul canal de sortie.

### ğŸ¯ Objectif

* **AggrÃ©ger les rÃ©sultats** venant de plusieurs sources concurrentes.
* Centraliser l'Ã©coute des rÃ©sultats.

### ğŸ§  Illustration

Voici une fonction `merge` qui fait du fan-in :

```go
func merge(done <-chan struct{}, cs ...<-chan int) <-chan int {
    var wg sync.WaitGroup
    out := make(chan int)

    output := func(c <-chan int) {
        defer wg.Done()
        for {
            select {
            case n, ok := <-c:
                if !ok {
                    return
                }
                out <- n
            case <-done:
                return
            }
        }
    }

    wg.Add(len(cs))
    for _, c := range cs {
        go output(c)
    }

    // Ferme le canal de sortie une fois que tous les workers sont terminÃ©s
    go func() {
        wg.Wait()
        close(out)
    }()

    return out
}
```

Dans le `main` :

```go
for n := range merge(done, c1, c2) {
    fmt.Println(n)
}
```

---

## ğŸ§­ RÃ©sumÃ©

| Pattern     | Description                                                       | Exemple               |
| ----------- | ----------------------------------------------------------------- | --------------------- |
| **Fan-out** | Plusieurs workers lisent Ã  partir du mÃªme canal d'entrÃ©e          | `square` en parallÃ¨le |
| **Fan-in**  | Un seul canal de sortie agrÃ¨ge les rÃ©sultats de plusieurs workers | `merge`               |

---

## Stopping short

Bien sÃ»r ! Dans le contexte de la **concurrence en Go**, **"Stopping short"** signifie **arrÃªter prÃ©maturÃ©ment un pipeline** dÃ¨s quâ€™on nâ€™a plus besoin de tous les rÃ©sultats.

Cela Ã©vite :

* de gaspiller des ressources CPU
* dâ€™avoir des goroutines orphelines
* des fuites mÃ©moire (goroutines qui bloquent Ã  attendre des donnÃ©es)

---

## ğŸ“ Cas concret

Imaginons que tu veux juste **le premier rÃ©sultat valide** dâ€™un pipeline, puis **tout arrÃªter**.

---

## ğŸ§ª Exemple de problÃ¨me sans "stopping short"

```go
func gen(nums ...int) <-chan int {
    out := make(chan int)
    go func() {
        for _, n := range nums {
            out <- n
        }
        close(out)
    }()
    return out
}

func square(in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        for n := range in {
            out <- n * n
        }
        close(out)
    }()
    return out
}

func main() {
    in := gen(2, 3, 4, 5, 6, 7)
    out := square(in)

    fmt.Println(<-out) // on lit juste le premier rÃ©sultat

    // âŒ Mais les goroutines continuent Ã  tourner !
}
```

---

## âœ… Solution : `done` channel (Stopping short)

Ajoutons un **canal `done`** pour permettre lâ€™annulation :

```go
func gen(done <-chan struct{}, nums ...int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for _, n := range nums {
            select {
            case out <- n:
            case <-done:
                return
            }
        }
    }()
    return out
}

func square(done <-chan struct{}, in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for {
            select {
            case n, ok := <-in:
                if !ok {
                    return
                }
                select {
                case out <- n * n:
                case <-done:
                    return
                }
            case <-done:
                return
            }
        }
    }()
    return out
}
```

Et dans le `main` :

```go
func main() {
    done := make(chan struct{})
    defer close(done)

    in := gen(done, 2, 3, 4, 5, 6)
    out := square(done, in)

    fmt.Println(<-out) // âœ… on lit un seul rÃ©sultat
    // Le defer close(done) arrÃªte tout le pipeline proprement
}
```

---

## ğŸ§  Pourquoi câ€™est important ?

* Sans cancellation, des goroutines peuvent rester bloquÃ©es.
* Go ne **garbage collect** pas les goroutines actives.
* Bien gÃ©rer "stopping short" est crucial pour des pipelines robustes, rÃ©actifs et sans fuite.

---

### Examples

Parfait ! Voici comment gÃ©rer **"stopping short"** en Go en utilisant le **package `context`**, qui est la **mÃ©thode recommandÃ©e** dans les applications modernes.

---

## âœ… Pourquoi `context.Context` ?

Le package `context` permet de :

* dÃ©finir un **timeout** ou une **deadline**
* propager une **annulation** Ã  toutes les goroutines concernÃ©es
* Ã©viter dâ€™avoir Ã  gÃ©rer manuellement un canal `done`

---

## ğŸ”§ Exemple avec `context.WithCancel`

### ğŸ” Pipeline avec contexte

```go
func gen(ctx context.Context, nums ...int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for _, n := range nums {
            select {
            case <-ctx.Done():
                return
            case out <- n:
            }
        }
    }()
    return out
}

func square(ctx context.Context, in <-chan int) <-chan int {
    out := make(chan int)
    go func() {
        defer close(out)
        for {
            select {
            case <-ctx.Done():
                return
            case n, ok := <-in:
                if !ok {
                    return
                }
                select {
                case out <- n * n:
                case <-ctx.Done():
                    return
                }
            }
        }
    }()
    return out
}
```

### ğŸ§ª Utilisation dans `main`

```go
func main() {
    ctx, cancel := context.WithCancel(context.Background())
    defer cancel() // ğŸ›‘ dÃ©clenche l'annulation Ã  la fin

    in := gen(ctx, 2, 3, 4, 5)
    out := square(ctx, in)

    // Lire seulement le premier rÃ©sultat
    fmt.Println(<-out)

    // âœ… Les goroutines s'arrÃªtent automatiquement grÃ¢ce au `context`
}
```

---

## â° Variante avec `context.WithTimeout`

On peut aussi **arrÃªter automatiquement aprÃ¨s un dÃ©lai** :

```go
ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)
defer cancel()
```

Cela fonctionne avec les mÃªmes fonctions `gen` et `square`.

---

## ğŸ§  Avantages de `context`

| Avantage     | Description                                                        |
| ------------ | ------------------------------------------------------------------ |
| âœ… CentralisÃ© | Toutes les annulations passent par un seul objet `ctx`             |
| âœ… IntÃ©grÃ©    | Beaucoup de bibliothÃ¨ques Go le supportent nativement              |
| âœ… Lisible    | Moins de code personnalisÃ© Ã  gÃ©rer (pas de canal `done` Ã  la main) |

---

Bien sÃ»r ! En Go, **explicit cancellation** (annulation explicite) signifie que **tu contrÃ´les manuellement le moment oÃ¹ un pipeline ou une sÃ©rie de goroutines doit sâ€™arrÃªter**, au lieu dâ€™attendre quâ€™elles terminent dâ€™elles-mÃªmes ou quâ€™un timeout survienne.

---

## âœ… Quand lâ€™utiliser ?

Tu veux arrÃªter **dÃ¨s que :**

* tu as obtenu un rÃ©sultat satisfaisant,
* une erreur est survenue,
* lâ€™utilisateur a annulÃ© lâ€™opÃ©ration,
* tu ne veux plus traiter le reste des donnÃ©es.

---

## ğŸ§± Moyens dâ€™implÃ©menter une cancellation explicite

### 1. Avec un **canal `done`** (approche manuelle)

Câ€™est la forme "brute" d'annulation explicite. Tu fermes un canal pour signaler que tout doit sâ€™arrÃªter.

#### Exemple :

```go
done := make(chan struct{})
defer close(done) // âœ‹ Annulation explicite

in := gen(done, 1, 2, 3, 4)
out := square(done, in)

fmt.Println(<-out) // on lit juste le premier rÃ©sultat
```

Dans les fonctions `gen` et `square`, tu vÃ©rifies rÃ©guliÃ¨rement :

```go
select {
case <-done:
    return
default:
    // continuer normalement
}
```

---

### 2. Avec `context.WithCancel()` (approche recommandÃ©e)

Câ€™est la mÃ©thode moderne et prÃ©fÃ©rÃ©e en Go. Elle fournit une fonction `cancel()` que tu peux appeler **explicitement**.

#### Exemple :

```go
ctx, cancel := context.WithCancel(context.Background())
defer cancel() // ğŸ‘ˆ annulation explicite quand la fonction se termine

in := gen(ctx, 1, 2, 3)
out := square(ctx, in)

fmt.Println(<-out) // on lit un seul rÃ©sultat

cancel() // ğŸ›‘ explicitement, on arrÃªte toutes les goroutines qui Ã©coutent ce contexte
```

Et dans `gen` / `square`, tu Ã©coutes :

```go
select {
case <-ctx.Done():
    return
}
```

---

## ğŸ§  Pourquoi faire une cancellation explicite ?

| ProblÃ¨me Ã©vitÃ©                       | Comment ?                                                                  |
| ------------------------------------ | -------------------------------------------------------------------------- |
| Goroutines qui tournent dans le vide | On les arrÃªte via `cancel()` ou `close(done)`                              |
| Fuites mÃ©moire                       | Pas de goroutines bloquÃ©es inutilement                                     |
| RÃ©activitÃ©                           | Le programme rÃ©agit immÃ©diatement dÃ¨s que tu nâ€™as plus besoin de continuer |

---

## ğŸ” RÃ©sumÃ©

| Type              | MÃ©canisme     | Utilisation                       |
| ----------------- | ------------- | --------------------------------- |
| Canal `done`      | `close(done)` | Simple mais bas niveau            |
| `context.Context` | `cancel()`    | RecommandÃ©, flexible, standardisÃ© |

---

### Digesting a tree

Bien sÃ»r ! Le pattern **"Digesting a tree"** en Go, dans le contexte du blog [Go Concurrency Patterns: Pipelines and Cancellation](https://go.dev/blog/pipelines), signifie **parcourir une structure arborescente (comme un systÃ¨me de fichiers) de maniÃ¨re concurrente**, tout en **contrÃ´lant les ressources** (comme le nombre de goroutines) et en gÃ©rant l'annulation.

---

## ğŸŒ³ Quâ€™est-ce quâ€™un arbre ici ?

Un **arbre** est une structure rÃ©cursive : un **nÅ“ud** peut avoir plusieurs **sous-nÅ“uds**. Exemple typique : les **dossiers et fichiers** dans un systÃ¨me de fichiers.

---

## ğŸ§  Objectif : digÃ©rer un arbre

Cela veut dire :

1. Parcourir lâ€™arbre (ex : tous les fichiers dâ€™un rÃ©pertoire),
2. Lister les fichiers (ou effectuer une action sur chaque nÅ“ud),
3. GÃ©rer la **concurrence** (pour aller plus vite),
4. **Limiter les ressources** (Ã©viter dâ€™ouvrir 1000 goroutines),
5. Supporter lâ€™**annulation** (si on veut arrÃªter Ã  mi-chemin).

---

## ğŸ“¦ Exemple tirÃ© du blog : `du` (disk usage)

Lâ€™outil `du` parcourt un dossier et calcule la taille totale des fichiers. Voici lâ€™idÃ©e :

```go
func walkDir(dir string, n *sync.WaitGroup, fileSizes chan<- int64) {
    defer n.Done()
    for _, entry := range entries(dir) {
        if entry.IsDir() {
            n.Add(1)
            subdir := filepath.Join(dir, entry.Name())
            go walkDir(subdir, n, fileSizes)
        } else {
            fileSizes <- entry.Size()
        }
    }
}
```

---

## âœ‹ ProblÃ¨me : trop de goroutines

Si tu as des milliers de sous-dossiers, tu risques de lancer trop de goroutines. Solution :

### âœ… Limiter le parallÃ©lisme avec un **semaphore** (canal tamponnÃ©)

```go
var sema = make(chan struct{}, 20) // max 20 goroutines concurrentes

func entries(dir string) []os.FileInfo {
    sema <- struct{}{}           // acquire
    defer func() { <-sema }()    // release
    // lire les fichiers dans dir
}
```

---

## ğŸš¨ Et si on veut arrÃªter au milieu ? (Digesting + cancellation)

Tu ajoutes un `done` ou un `context.Context` :

```go
func walkDir(ctx context.Context, dir string, n *sync.WaitGroup, fileSizes chan<- int64) {
    defer n.Done()
    for _, entry := range entries(dir) {
        select {
        case <-ctx.Done():
            return
        default:
        }

        if entry.IsDir() {
            n.Add(1)
            subdir := filepath.Join(dir, entry.Name())
            go walkDir(ctx, subdir, n, fileSizes)
        } else {
            select {
            case fileSizes <- entry.Size():
            case <-ctx.Done():
                return
            }
        }
    }
}
```

---

## ğŸ§­ RÃ©sumÃ© : Digesting a tree

| Ã‰lÃ©ment                     | RÃ´le                                                        |
| --------------------------- | ----------------------------------------------------------- |
| Arbre                       | Structure rÃ©cursive Ã  parcourir (ex : systÃ¨me de fichiers)  |
| Goroutines                  | Chaque sous-dossier peut Ãªtre explorÃ© en parallÃ¨le          |
| SÃ©maphore (canal tamponnÃ©)  | Limite le nombre de goroutines concurrentes                 |
| `done` ou `context.Context` | Permet dâ€™annuler proprement le parcours                     |
| `sync.WaitGroup`            | Attend que tout le traitement soit terminÃ© avant de quitter |

---

## Parallel digestion

Bien sÃ»r ! En Go, **Parallel Digestion** (ou "digestion parallÃ¨le") est une extension du pattern **"Digesting a tree"**, oÃ¹ tu parcours une **structure arborescente de faÃ§on concurrente** pour **accÃ©lÃ©rer le traitement** de chaque branche ou nÅ“ud.

---

## ğŸ§  Objectif de Parallel Digestion

* Traiter **chaque sous-partie de lâ€™arbre en parallÃ¨le**.
* Utiliser des **goroutines pour explorer plusieurs branches simultanÃ©ment**.
* GÃ©rer les **ressources**, les **erreurs**, et la **cancellation** proprement.

---

## ğŸ“¦ Exemple concret : exploration d'un systÃ¨me de fichiers

Imaginons que tu veux calculer la taille totale de tous les fichiers dans un rÃ©pertoire (comme lâ€™outil `du`), **mais en parallÃ¨le**.

---

### ğŸ§± Ã‰tapes typiques de parallel digestion

1. **Lister les sous-dossiers** dâ€™un rÃ©pertoire.
2. **Lancer une goroutine** pour chaque sous-dossier.
3. **Envoyer les rÃ©sultats** sur un canal.
4. **Coordonner** avec `sync.WaitGroup`.
5. **Limiter le nombre de goroutines** avec un **sÃ©maphore** (canal tamponnÃ©).
6. **Annuler proprement** via `context.Context`.

---

## ğŸ§‘â€ğŸ’» Code simplifiÃ© : Parallel Digestion

```go
func walkDir(ctx context.Context, dir string, wg *sync.WaitGroup, sizes chan<- int64, sema chan struct{}) {
    defer wg.Done()

    select {
    case sema <- struct{}{}: // acquire token
    case <-ctx.Done():
        return
    }
    defer func() { <-sema }() // release token

    entries, err := os.ReadDir(dir)
    if err != nil {
        return
    }

    for _, entry := range entries {
        if entry.IsDir() {
            subdir := filepath.Join(dir, entry.Name())
            wg.Add(1)
            go walkDir(ctx, subdir, wg, sizes, sema)
        } else {
            info, err := entry.Info()
            if err == nil {
                select {
                case sizes <- info.Size():
                case <-ctx.Done():
                    return
                }
            }
        }
    }
}
```

### ğŸ” Utilisation :

```go
func main() {
    ctx, cancel := context.WithCancel(context.Background())
    defer cancel()

    sizes := make(chan int64)
    var wg sync.WaitGroup
    sema := make(chan struct{}, 20) // max 20 concurrent goroutines

    root := "/some/dir"

    wg.Add(1)
    go walkDir(ctx, root, &wg, sizes, sema)

    go func() {
        wg.Wait()
        close(sizes)
    }()

    var total int64
    for size := range sizes {
        total += size
    }

    fmt.Printf("Total size: %.1f MB\n", float64(total)/1e6)
}
```

---

## âš™ï¸ RÃ©sumÃ© de Parallel Digestion

| Composant         | RÃ´le                                                            |
| ----------------- | --------------------------------------------------------------- |
| `goroutines`      | Parcours parallÃ¨le de lâ€™arbre                                   |
| `sync.WaitGroup`  | Synchronise la fin de toutes les explorations                   |
| `chan struct{}`   | SÃ©maphore pour limiter le nombre de goroutines                  |
| `context.Context` | Permet une annulation propre du traitement                      |
| `chan int64`      | Canal pour transmettre les rÃ©sultats (ex : tailles de fichiers) |

---

## ğŸ“Œ Pourquoi câ€™est utile ?

* Câ€™est **scalable** : les dossiers/projets Ã©normes sont traitÃ©s efficacement.
* Câ€™est **propre** : les erreurs et annulations sont bien gÃ©rÃ©es.
* Câ€™est **rapide** : tu exploites tous les cÅ“urs CPU disponibles.

---

## Bounded parallelism

Bien sÃ»r ! Le concept de **Bounded Parallelism** (ou **parallÃ©lisme bornÃ©**) en Go consiste Ã  **limiter le nombre de goroutines exÃ©cutÃ©es en parallÃ¨le** pour :

* Ã©viter de saturer le CPU ou la mÃ©moire,
* respecter des quotas (ex : nombre maximum de connexions Ã  une API, nombre de fichiers ouverts, etc.),
* garder un **contrÃ´le fin sur la consommation de ressources**.

---

## ğŸ“ Pourquoi pas un parallÃ©lisme illimitÃ© ?

MÃªme si Go permet de lancer facilement des milliers de goroutines, cela peut poser problÃ¨me :

* Trop de goroutines = trop de **RAM** utilisÃ©e.
* Certaines opÃ©rations sont limitÃ©es (ex : nombre max de fichiers ouverts).
* Tu risques de crÃ©er une **tempÃªte de traitement** difficile Ã  gÃ©rer.

---

## âœ… Solution : canal tamponnÃ© = **sÃ©maphore**

Tu utilises un **canal de type `chan struct{}` avec capacitÃ© fixe** comme **sÃ©maphore** pour limiter le nombre de goroutines **actives en mÃªme temps**.

---

## ğŸ§± Exemple minimal : 5 goroutines max

```go
var sem = make(chan struct{}, 5) // maximum 5 goroutines en mÃªme temps

func process(i int) {
    sem <- struct{}{}        // ğŸ›‘ bloque si 5 goroutines sont dÃ©jÃ  en cours
    go func() {
        defer func() { <-sem }() // âœ… libÃ¨re une place Ã  la fin

        fmt.Printf("Processing item %d\n", i)
        time.Sleep(1 * time.Second)
    }()
}
```

Et dans ta boucle principale :

```go
for i := 0; i < 20; i++ {
    process(i)
}

// Attendre la fin (sinon le programme se termine avant)
time.Sleep(5 * time.Second)
```

---

## ğŸ§‘â€ğŸ”§ Avec `sync.WaitGroup` pour attendre proprement

```go
var wg sync.WaitGroup
sem := make(chan struct{}, 5)

for i := 0; i < 20; i++ {
    sem <- struct{}{}
    wg.Add(1)

    go func(i int) {
        defer func() {
            <-sem
            wg.Done()
        }()
        fmt.Printf("Job %d started\n", i)
        time.Sleep(1 * time.Second)
    }(i)
}

wg.Wait()
fmt.Println("All done")
```

---

## ğŸ§  RÃ©sumÃ© : Bounded Parallelism

| Ã‰lÃ©ment                  | RÃ´le                                   |
| ------------------------ | -------------------------------------- |
| `chan struct{}` tamponnÃ© | Sert de **sÃ©maphore**                  |
| `len(sem)`               | Donne le nombre de goroutines en cours |
| `WaitGroup`              | Synchronise la fin des tÃ¢ches          |

---

## ğŸ“Œ Cas dâ€™usage typiques

* Explorer un systÃ¨me de fichiers (comme dans `walkDir`)
* TÃ©lÃ©chargements concurrents mais limitÃ©s
* Traitement de requÃªtes API sans dÃ©passer les quotas
* Compression/conversion de fichiers en parallÃ¨le

---

Souhaites-tu un exemple complet avec **context**, **bounded parallelism** et **fan-in/out** combinÃ©s ?

### Examples

Parfaitâ€¯! Voici un **exemple complet en Go** combinant :

* âœ… **Context** pour la cancellation,
* âœ… **Bounded parallelism** pour limiter les ressources,
* âœ… **Fan-out** pour distribuer le travail,
* âœ… **Fan-in** pour collecter les rÃ©sultats.

---

## ğŸ¯ Objectif du code

> Traiter une liste de fichiers (fictifs ici), en parallÃ¨le, mais avec au plus 5 goroutines actives, et sâ€™arrÃªter proprement si l'utilisateur annule.

---

## ğŸ§‘â€ğŸ’» Code Go Complet

```go
package main

import (
    "context"
    "fmt"
    "math/rand"
    "sync"
    "time"
)

func main() {
    ctx, cancel := context.WithCancel(context.Background())
    defer cancel()

    // Simulons une liste de fichiers Ã  traiter
    files := []string{"a.txt", "b.txt", "c.txt", "d.txt", "e.txt", "f.txt", "g.txt"}

    results := make(chan string)
    sem := make(chan struct{}, 5) // max 5 goroutines
    var wg sync.WaitGroup

    // Fan-out: une goroutine par fichier
    for _, file := range files {
        select {
        case <-ctx.Done():
            break
        case sem <- struct{}{}:
            wg.Add(1)
            go func(f string) {
                defer func() {
                    <-sem
                    wg.Done()
                }()

                result, err := processFile(ctx, f)
                if err != nil {
                    fmt.Printf("Error processing %s: %v\n", f, err)
                    return
                }

                select {
                case results <- result:
                case <-ctx.Done():
                    return
                }
            }(file)
        }
    }

    // Fan-in: collecteur des rÃ©sultats
    go func() {
        wg.Wait()
        close(results)
    }()

    // Lire les rÃ©sultats, ou arrÃªter Ã  une condition
    for r := range results {
        fmt.Println("RÃ©sultat:", r)

        if r == "b.txt traitÃ©" {
            fmt.Println("Condition atteinte, annulation.")
            cancel() // ğŸ›‘ annulation explicite
        }
    }

    fmt.Println("âœ… Tous les traitements terminÃ©s ou annulÃ©s.")
}

// Simule un traitement de fichier
func processFile(ctx context.Context, name string) (string, error) {
    delay := time.Duration(rand.Intn(1000)+500) * time.Millisecond
    select {
    case <-time.After(delay): // simule le travail
        return name + " traitÃ©", nil
    case <-ctx.Done():
        return "", ctx.Err()
    }
}
```

---

## ğŸ“Œ Ce que ce code montre

| Pattern                 | OÃ¹ il est utilisÃ©                                |
| ----------------------- | ------------------------------------------------ |
| **Context**             | `context.WithCancel()` et `ctx.Done()`           |
| **Fan-out**             | Une goroutine par fichier                        |
| **Fan-in**              | Canal `results` collectant tous les rÃ©sultats    |
| **Bounded parallelism** | Canal `sem` limitant Ã  5 goroutines concurrentes |

---

## ğŸ§ª RÃ©sultat attendu (alÃ©atoire)

```
RÃ©sultat: c.txt traitÃ©
RÃ©sultat: b.txt traitÃ©
Condition atteinte, annulation.
RÃ©sultat: e.txt traitÃ©
âœ… Tous les traitements terminÃ©s ou annulÃ©s.
```

---

