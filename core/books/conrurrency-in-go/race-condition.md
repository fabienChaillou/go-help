Une **race condition** (ou **condition de concurrence**) en Go â€” comme dans beaucoup de langages concurrents â€” se produit lorsque **deux ou plusieurs goroutines accÃ¨dent Ã  une mÃªme variable partagÃ©e en mÃªme temps**, **et qu'au moins une d'entre elles effectue une Ã©criture**. Cela peut provoquer un comportement non dÃ©terministe, c'est-Ã -dire que le rÃ©sultat du programme peut varier Ã  chaque exÃ©cution.

### ExpliquÃ© simplement

Imagine que deux personnes essaient de modifier un mÃªme fichier en mÃªme temps sans coordination. L'une commence Ã  Ã©crire pendant que l'autre lit ou Ã©crit aussi. Le contenu final du fichier dÃ©pendra de qui a Ã©tÃ© le plus rapide â€” c'est une race condition.

---

### Exemple simple en Go

```go
package main

import (
    "fmt"
    "time"
)

var counter int

func increment() {
    for i := 0; i < 1000; i++ {
        counter++
    }
}

func main() {
    go increment()
    go increment()

    time.Sleep(1 * time.Second)
    fmt.Println("Counter:", counter)
}
```

#### Que se passe-t-il ici ?

* Deux goroutines appellent `increment()`, chacune essayant dâ€™augmenter `counter`.
* `counter++` nâ€™est **pas une opÃ©ration atomique** â€” elle lit, incrÃ©mente, puis Ã©crit.
* RÃ©sultat : **le compteur nâ€™atteindra probablement pas 2000**, car des mises Ã  jour sont Ã©crasÃ©es.

---

### Comment dÃ©tecter les race conditions en Go ?

Go fournit un outil trÃ¨s utile :

```bash
go run -race main.go
```

Ce flag permet de dÃ©tecter les accÃ¨s concurrents Ã  une variable et vous alertera sâ€™il y a un problÃ¨me.

---

### Comment Ã©viter les race conditions ?

Voici plusieurs mÃ©thodes :

#### 1. **Mutex (verrou)**

```go
import "sync"

var mu sync.Mutex

func increment() {
    for i := 0; i < 1000; i++ {
        mu.Lock()
        counter++
        mu.Unlock()
    }
}
```

#### 2. **Canaux (channels)** â€“ modÃ¨le de communication par message

```go
func increment(ch chan int) {
    for i := 0; i < 1000; i++ {
        ch <- 1
    }
}

func main() {
    ch := make(chan int)
    go increment(ch)
    go increment(ch)

    go func() {
        for i := 0; i < 2000; i++ {
            counter += <-ch
        }
    }()

    time.Sleep(1 * time.Second)
    fmt.Println("Counter:", counter)
}
```

#### 3. **sync/atomic** â€“ opÃ©rations atomiques rapides

```go
import "sync/atomic"

var counter int32

func increment() {
    for i := 0; i < 1000; i++ {
        atomic.AddInt32(&counter, 1)
    }
}
```

---

### Ã€ retenir

* Une race condition rend le programme imprÃ©visible.
* Utilisez `-race` pendant le dÃ©veloppement pour les dÃ©tecter.
* ProtÃ©gez les accÃ¨s concurrents avec `sync.Mutex`, `sync/atomic` ou des `chan`.

Souhaites-tu un exemple avec un scÃ©nario plus concret (ex : accÃ¨s concurrent Ã  une base de donnÃ©es ou Ã  une map) ?

Prenons un exemple **concret** : plusieurs goroutines accÃ¨dent Ã  une **map partagÃ©e** (simulant un cache mÃ©moire), ce qui peut provoquer une race condition. Ensuite, on corrigera ce problÃ¨me avec un `sync.Mutex`.

---

## ğŸ”¥ Exemple 1 : AccÃ¨s concurrent Ã  une map (race condition)

```go
package main

import (
    "fmt"
    "time"
)

var cache = make(map[string]string)

func writeToCache(key, value string) {
    cache[key] = value
}

func readFromCache(key string) string {
    return cache[key]
}

func main() {
    for i := 0; i < 10; i++ {
        go writeToCache(fmt.Sprintf("key%d", i), fmt.Sprintf("value%d", i))
        go readFromCache(fmt.Sprintf("key%d", i))
    }

    time.Sleep(1 * time.Second)
    fmt.Println("Cache:", cache)
}
```

### ğŸ§¨ ProblÃ¨me

* La map `cache` est **modifiÃ©e** et **lue** en mÃªme temps par plusieurs goroutines.
* En Go, **les maps ne sont pas thread-safe**, donc ce code peut panic ou donner des rÃ©sultats imprÃ©visibles.
* Lance le avec `go run -race` pour dÃ©tecter les conflits.

---

## âœ… Exemple 2 : Version corrigÃ©e avec `sync.Mutex`

```go
package main

import (
    "fmt"
    "sync"
    "time"
)

var (
    cache = make(map[string]string)
    mu    sync.Mutex
)

func writeToCache(key, value string) {
    mu.Lock()
    cache[key] = value
    mu.Unlock()
}

func readFromCache(key string) string {
    mu.Lock()
    defer mu.Unlock()
    return cache[key]
}

func main() {
    for i := 0; i < 10; i++ {
        go writeToCache(fmt.Sprintf("key%d", i), fmt.Sprintf("value%d", i))
        go readFromCache(fmt.Sprintf("key%d", i))
    }

    time.Sleep(1 * time.Second)
    fmt.Println("Cache:", cache)
}
```

### âœ… Comportement

* Le `sync.Mutex` empÃªche les accÃ¨s simultanÃ©s Ã  la map.
* Le programme devient **sÃ»r et dÃ©terministe**.

---

Tu veux que je te montre comment faire Ã§a avec des `channels` ou avec `sync.Map` (une map concurrente intÃ©grÃ©e Ã  Go) ?

Parfait, voyons deux alternatives Ã©lÃ©gantes Ã  `sync.Mutex` : **`channels`** (modÃ¨le CSP de Go) et **`sync.Map`**, une map concurrente native.

---

## âœ… Option 1 : Utiliser des **channels** (approche orientÃ©e message)

Ici, on encapsule lâ€™accÃ¨s Ã  la map dans une goroutine "gestionnaire" qui reÃ§oit les opÃ©rations via des canaux.

```go
package main

import (
    "fmt"
    "time"
)

type request struct {
    key      string
    value    string
    isWrite  bool
    response chan string
}

func cacheManager(reqChan chan request) {
    cache := make(map[string]string)
    for req := range reqChan {
        if req.isWrite {
            cache[req.key] = req.value
        } else {
            req.response <- cache[req.key]
        }
    }
}

func main() {
    reqChan := make(chan request)

    // Lancement du gestionnaire de cache
    go cacheManager(reqChan)

    // Ã‰criture
    for i := 0; i < 10; i++ {
        reqChan <- request{
            key:     fmt.Sprintf("key%d", i),
            value:   fmt.Sprintf("value%d", i),
            isWrite: true,
        }
    }

    // Lecture
    for i := 0; i < 10; i++ {
        resp := make(chan string)
        reqChan <- request{
            key:      fmt.Sprintf("key%d", i),
            isWrite:  false,
            response: resp,
        }
        fmt.Printf("key%d = %s\n", i, <-resp)
    }

    time.Sleep(500 * time.Millisecond)
}
```

### âœ”ï¸ Avantages

* Pas de besoin de mutex : un seul gestionnaire contrÃ´le lâ€™accÃ¨s.
* Approche trÃ¨s Go-style (inspirÃ©e dâ€™Erlang et CSP).

---

## âœ… Option 2 : Utiliser `sync.Map` (map thread-safe intÃ©grÃ©e)

`sync.Map` est optimisÃ©e pour un grand nombre de lectures et un petit nombre dâ€™Ã©critures.

```go
package main

import (
    "fmt"
    "sync"
)

var cache sync.Map

func writeToCache(key, value string) {
    cache.Store(key, value)
}

func readFromCache(key string) string {
    value, ok := cache.Load(key)
    if ok {
        return value.(string)
    }
    return "not found"
}

func main() {
    for i := 0; i < 10; i++ {
        go writeToCache(fmt.Sprintf("key%d", i), fmt.Sprintf("value%d", i))
        go func(i int) {
            fmt.Println(readFromCache(fmt.Sprintf("key%d", i)))
        }(i)
    }

    // Juste pour attendre les goroutines (dans la vraie vie, utilise sync.WaitGroup)
    fmt.Scanln()
}
```

### âœ”ï¸ Avantages

* Pas besoin de gÃ©rer la synchronisation soi-mÃªme.
* Utile dans les cas de **cache partagÃ© trÃ¨s lu, peu Ã©crit**.
* Interface diffÃ©rente de `map` (mÃ©thodes `Store`, `Load`, `Delete`, `Range`).

---

Souhaites-tu que je tâ€™intÃ¨gre lâ€™un de ces modÃ¨les dans un microservice REST (ex. cache utilisateur en mÃ©moire) ?

TrÃ¨s bienâ€¯! Voici un petit **microservice REST en Go avec Gin**, qui expose une API de type **cache clÃ©/valeur en mÃ©moire**.

ğŸ› ï¸ Il utilise :

* **Gin** pour le serveur HTTP,
* **`sync.Map`** pour stocker les donnÃ©es en mÃ©moire, de maniÃ¨re **thread-safe**,
* JSON pour les entrÃ©es/sorties.

---

## ğŸ“¦ Structure des endpoints

| MÃ©thode | Endpoint      | Description             |
| ------- | ------------- | ----------------------- |
| `GET`   | `/cache/:key` | Lire une valeur par clÃ© |
| `POST`  | `/cache`      | Ã‰crire une clÃ©/valeur   |

---

## âœ… Code complet avec `sync.Map`

```go
package main

import (
    "github.com/gin-gonic/gin"
    "net/http"
    "sync"
)

var cache sync.Map

type CacheEntry struct {
    Key   string `json:"key" binding:"required"`
    Value string `json:"value" binding:"required"`
}

func main() {
    r := gin.Default()

    // POST /cache
    r.POST("/cache", func(c *gin.Context) {
        var entry CacheEntry
        if err := c.ShouldBindJSON(&entry); err != nil {
            c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
            return
        }

        cache.Store(entry.Key, entry.Value)
        c.JSON(http.StatusOK, gin.H{"message": "stored"})
    })

    // GET /cache/:key
    r.GET("/cache/:key", func(c *gin.Context) {
        key := c.Param("key")
        if value, ok := cache.Load(key); ok {
            c.JSON(http.StatusOK, gin.H{"key": key, "value": value})
        } else {
            c.JSON(http.StatusNotFound, gin.H{"error": "key not found"})
        }
    })

    r.Run(":8080")
}
```

---

## ğŸ§ª Test rapide avec `curl`

```bash
# Stocker une valeur
curl -X POST http://localhost:8080/cache \
    -H "Content-Type: application/json" \
    -d '{"key":"user42", "value":"Alice"}'

# RÃ©cupÃ©rer la valeur
curl http://localhost:8080/cache/user42
```

---

### ğŸ§© Variante possible

Souhaites-tu une version avec un **mutex + map** au lieu de `sync.Map`, ou bien avec un **TTL (expiration)** des entrÃ©es comme un vrai cache ?
